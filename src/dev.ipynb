{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \n",
    "    min_val = np.min(np.min(data, axis=0), axis=0)\n",
    "    data = data - min_val\n",
    "\n",
    "    max_val = np.max(np.max(data, axis=0), axis=0)\n",
    "    data = data / (max_val + 1e-7)\n",
    "    \n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDATA(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        data = np.asarray(data, dtype=np.float32)\n",
    "        norm_data = normalize(data)\n",
    "        seq_data = []\n",
    "        for i in range(len(norm_data) - seq_len + 1):\n",
    "            x = norm_data[i : i + seq_len]\n",
    "            seq_data.append(x)\n",
    "        self.samples = []\n",
    "        idx = torch.randperm(len(seq_data))\n",
    "        for i in range(len(seq_data)):\n",
    "            self.samples.append(seq_data[idx[i]])\n",
    "        self.samples = np.asarray(self.samples, dtype=np.float32)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(subset_len=25000):\n",
    "    \n",
    "    data_dir = f'./preprocessing/data/meter_data/LCL-June2015v2_0.csv'\n",
    "    cond_data_dir = \"./preprocessing/data/conditioning_data/weather_hourly_darksky.csv\"\n",
    "    \n",
    "    data = pd.read_csv(data_dir)\n",
    "    data.replace('Null', 0, inplace=True)\n",
    "    \n",
    "    cond_data = pd.read_csv(cond_data_dir)\n",
    "    cond_data = cond_data[[\"time\", \"humidity\", \"temperature\", \"windSpeed\"]]\n",
    "    cond_data['time'] = pd.to_datetime(cond_data['time'])\n",
    "    cond_data.set_index('time', inplace=True)\n",
    "    cond_data = cond_data.resample('30min').interpolate(method='linear')\n",
    "    \n",
    "    if subset_len != \"None\":\n",
    "       data = data.iloc[:subset_len, 3]\n",
    "       cond_data = cond_data.iloc[:subset_len, :]\n",
    "    else:    \n",
    "        data = data.iloc[:len(cond_data), 3] #for this test dataset cond data is less than actual data\n",
    "    \n",
    "    return data, cond_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_house_zero():\n",
    "    data_dir_y1 = './preprocessing/data/meter_data/48190963_Loads_hourly.csv'\n",
    "    data_dir_y2 = './preprocessing/data/meter_data/48190948_Loads_hourly.csv'\n",
    "\n",
    "    cond_data_dir_y1 = \"./preprocessing/data/conditioning_data/48190936_Weather.csv\"\n",
    "    cond_data_dir_y2 = \"./preprocessing/data/conditioning_data/48190930_Weather.csv\"\n",
    "\n",
    "    data_y1 = pd.read_csv(data_dir_y1)\n",
    "    data_y2 = pd.read_csv(data_dir_y2)\n",
    "\n",
    "    cond_data_y1 = pd.read_csv(cond_data_dir_y1, encoding='unicode_escape')\n",
    "    cond_data_y2 = pd.read_csv(cond_data_dir_y2, encoding='unicode_escape')\n",
    "\n",
    "    meter_data = pd.concat([data_y1.reset_index(drop=True), data_y2.reset_index(drop=True)], axis=0)\n",
    "    cond_data = pd.concat([cond_data_y1.reset_index(drop=True), cond_data_y2.reset_index(drop=True)], axis=0)\n",
    "\n",
    "    meter_data = meter_data[[\"NET\", \"Cooling\", \"PV_meter1_load (kW)\", \"PV_meter2_load (kW)\", \"Battery cabinet\", \"Sumppump\", \"Plug_Basement\", \"Solar rapid shutdown\"]]\n",
    "    cond_data = cond_data.iloc[:, 1:]\n",
    "    \n",
    "    return meter_data, cond_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(seq_len, subset_len, dataset=\"HouseZero\"):\n",
    "    if dataset == \"HouseZero\":\n",
    "        data, cond_data = data_preprocess_house_zero()\n",
    "    if dataset == \"LondonDataStore\":\n",
    "        data, cond_data = data_preprocess(subset_len) \n",
    "    \n",
    "    tts_split = 0.8\n",
    "    data = MakeDATA(data, seq_len)\n",
    "    cond_data = MakeDATA(cond_data, seq_len)\n",
    "    \n",
    "    train_size = int(len(data) * tts_split)\n",
    "    test_size = len(data) - train_size\n",
    "    train_data, test_data = random_split(data, [train_size, test_size])\n",
    "    \n",
    "    train_size = int(len(cond_data) * tts_split)\n",
    "    test_size = len(cond_data) - train_size\n",
    "    cond_data_train, cond_data_test = random_split(cond_data, [train_size, test_size])\n",
    "    \n",
    "    return train_data, test_data, cond_data_train, cond_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serve_data(seq_len, batch_size, subset_len=25000):\n",
    "    train_data, test_data, cond_data_train, cond_data_test = LoadData(seq_len=seq_len, subset_len=subset_len)\n",
    "    train_data, test_data, cond_data_train, cond_data_test= np.asarray(train_data), np.asarray(test_data), np.asarray(cond_data_train), np.asarray(cond_data_test)\n",
    "    \n",
    "    if len(train_data.shape) < 3:\n",
    "        train_data = np.expand_dims(train_data, axis=-1)\n",
    "        test_data = np.expand_dims(test_data, axis=-1)\n",
    "    \n",
    "    features = train_data.shape[2]\n",
    "    cond_features = cond_data_train.shape[2]\n",
    "    \n",
    "    print(f\"num of channels in transformer: {features} \\nnum of cond feature: {cond_features}\")\n",
    "\n",
    "    train_data, test_data, cond_data_train, cond_data_test = train_data.transpose(0,2,1), test_data.transpose(0,2,1), cond_data_train.transpose(0,2,1), cond_data_test.transpose(0,2,1)\n",
    "    print(f\"Train shape (batch, features, seq_len): {train_data.shape}\")\n",
    "    print(f\"Cond shape (batch, features, seq_len): {cond_data_train.shape}\")\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.from_numpy(train_data), torch.from_numpy(cond_data_train))\n",
    "    train_loader = DataLoader(train_dataset, batch_size)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.from_numpy(test_data), torch.from_numpy(cond_data_test))\n",
    "    test_loader = DataLoader(test_dataset, batch_size)\n",
    "\n",
    "    real_data, real_cond_data = next(iter(train_loader))\n",
    "    print(f\"batched data shape: {real_data.shape}\")\n",
    "    \n",
    "    return train_loader, test_loader, features, cond_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of channels in transformer: 8 \n",
      "num of cond feature: 8\n",
      "Train shape (batch, features, seq_len): (14024, 8, 15)\n",
      "Cond shape (batch, features, seq_len): (14024, 8, 15)\n",
      "batched data shape: torch.Size([32, 8, 15])\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, features, cond_features = serve_data(15, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
