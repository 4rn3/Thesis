{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf9a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from models.transformer_encoder import TransEncoder\n",
    "from ddpm.ddpm import GaussianDiffusion1D\n",
    "from evaluation.evaluation import KDEProgressionAnimator, vizual_comparison, plot_jsd_per_customer, plot_kde_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfccbdb",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ebe25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data\n",
    "seq_len = 12\n",
    "batch_size = 256\n",
    "\n",
    "#NN\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "latent_dim = 256\n",
    "cond_model = \"mlp\"\n",
    "num_layers = 6\n",
    "n_heads = 8\n",
    "lr = 1e-4\n",
    "betas = (0.9, 0.99)\n",
    "epochs = 6\n",
    "save_rate = 5\n",
    "\n",
    "## DDPM\n",
    "timesteps = 1000\n",
    "beta_schedule = \"cosine\"\n",
    "objective = \"pred_noise\"\n",
    "\n",
    "## Logging\n",
    "experiment_name = \"trans_dev\"\n",
    "logging_dir = f\"./logging/{experiment_name}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac50d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(logging_dir):\n",
    "    os.makedirs(logging_dir)\n",
    "    os.makedirs(os.path.join(logging_dir, \"viz/\"))\n",
    "    os.makedirs(os.path.join(logging_dir, \"jsd/\"))\n",
    "    os.makedirs(os.path.join(logging_dir, \"kde/\"))\n",
    "    os.makedirs(os.path.join(logging_dir, \"tensorboard/\"))\n",
    "    os.makedirs(os.path.join(logging_dir, \"weights/\"))\n",
    "    os.makedirs(os.path.join(logging_dir, \"ts_sample/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51fcd1e",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10548a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_DIR = \"./preprocessing/data/customer_led_network_revolution/preprocessed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3ef856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDATA(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        data = np.asarray(data, dtype=np.float32)\n",
    "        seq_data = []\n",
    "        for i in range(len(data) - seq_len + 1):\n",
    "            x = data[i : i + seq_len]\n",
    "            seq_data.append(x)\n",
    "        self.samples = np.asarray(seq_data, dtype=np.float32) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b79f4",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(PREPROCESSED_DIR, \"train.csv\"))\n",
    "val = pd.read_csv(os.path.join(PREPROCESSED_DIR, \"val.csv\"))\n",
    "test = pd.read_csv(os.path.join(PREPROCESSED_DIR, \"test.csv\"))\n",
    "cond_train = pd.read_csv(os.path.join(PREPROCESSED_DIR, \"cond_train.csv\"))\n",
    "cond_val = pd.read_csv(os.path.join(PREPROCESSED_DIR, \"cond_val.csv\"))\n",
    "cond_test = pd.read_csv(os.path.join(PREPROCESSED_DIR, \"cond_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"Date and Time of capture\", axis=1, inplace=True)\n",
    "val.drop(\"Date and Time of capture\", axis=1, inplace=True)\n",
    "test.drop(\"Date and Time of capture\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, val.shape, test.shape, cond_train.shape, cond_val.shape, cond_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b6440",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = np.asarray(MakeDATA(train, seq_len)).transpose(0, 2, 1)\n",
    "cond_train_seq = np.asarray(MakeDATA(cond_train, seq_len)).transpose(0, 2, 1)\n",
    "\n",
    "val_seq = np.asarray(MakeDATA(val, seq_len)).transpose(0, 2, 1)\n",
    "cond_val_seq = np.asarray(MakeDATA(cond_val, seq_len)).transpose(0, 2, 1)\n",
    "\n",
    "test_seq = np.asarray(MakeDATA(test, seq_len)).transpose(0, 2, 1)\n",
    "cond_test_seq = np.asarray(MakeDATA(cond_test, seq_len)).transpose(0, 2, 1)\n",
    "\n",
    "train_seq.shape, cond_train_seq.shape, test_seq.shape, cond_test_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc99567",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_seq), torch.from_numpy(cond_train_seq))\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(val_seq), torch.from_numpy(cond_val_seq))\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_seq), torch.from_numpy(cond_test_seq))\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2910dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_val, real_cond_data_val = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6d121",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = TransEncoder(features=train_seq.shape[1], latent_dim=latent_dim, num_heads=n_heads, num_layers=num_layers, cond_features=cond_train_seq.shape[1], cond_model=cond_model, device=device, seq_len=seq_len)\n",
    "\n",
    "ddpm = GaussianDiffusion1D(model, seq_length=seq_len, timesteps=timesteps, objective=objective, loss_type='l2', beta_schedule=beta_schedule)\n",
    "ddpm = ddpm.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(ddpm.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "writer = SummaryWriter(os.path.join(logging_dir, \"tensorboard/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b67e3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    \n",
    "    for i, (data, cond_data) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        cond_data = cond_data.float()\n",
    "        cond_data = cond_data.to(device)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        loss = ddpm(data, cond_data)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_number = 0\n",
    "best_val_loss = 1_000_000.\n",
    "snapshots = {}\n",
    "save_dir =  os.path.join(logging_dir, \"weights/\")\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    print('epoch {}:'.format(epoch_number + 1))\n",
    "    \n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    \n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (val_data, val_cond) in enumerate(val_loader):\n",
    "            val_data = val_data.to(device)\n",
    "        \n",
    "            val_cond = val_cond.float()\n",
    "            val_cond = val_cond.to(device)\n",
    "            val_loss = ddpm(val_data, val_cond)\n",
    "            \n",
    "            running_val_loss += val_loss\n",
    "    \n",
    "    avg_val_loss = running_val_loss / (i + 1)\n",
    "    print('Loss train {} val {}'.format(avg_loss, avg_val_loss))\n",
    "    \n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_val_loss },\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    writer.flush()\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch = epoch_number\n",
    "        best_ddpm_model = ddpm.state_dict()\n",
    "        best_optim_state_dict = optim.state_dict()\n",
    "        \n",
    "    \n",
    "    if epoch_number % save_rate == 0:\n",
    "        generated_sample = ddpm.sample(batch_size, real_cond_data_val.to(device))\n",
    "        generated_sample = generated_sample.cpu().numpy()\n",
    "        snapshots[epoch_number] = generated_sample\n",
    "        \n",
    "        model_name = f\"model_epoch_{epoch_number}_val_{avg_val_loss:.4f}.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch_number,\n",
    "            'diffusion_state_dict': ddpm.state_dict(),\n",
    "            'diffusion_optim_state_dict': optim.state_dict()},\n",
    "            os.path.join(save_dir, model_name))\n",
    "    \n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af0de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"best_model.pth\"\n",
    "torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'diffusion_state_dict': best_ddpm_model,\n",
    "    'diffusion_optim_state_dict': best_optim_state_dict},\n",
    "    os.path.join(logging_dir, \"weights/\", model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in snapshots.items():\n",
    "    plot_kde_samples(v, real_data_val,show=False, fpath=os.path.join(logging_dir, \"kde/\", f\"kde_epoch_{k}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2e9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a252d4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm.load_state_dict(torch.load(os.path.join(logging_dir, \"weights/\", \"best_model.pth\"))[\"diffusion_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98900634",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_test, real_cond_data_test = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samples = ddpm.sample(batch_size, real_cond_data_test.to(device))\n",
    "    samples = samples.cpu().numpy()\n",
    "\n",
    "print(f\"Samples shape: {samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d638ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizual_comparison(samples, real_data_test, os.path.join(logging_dir, \"viz/\", \"pca_umap_tsne.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_jsd_per_customer(samples, real_data_test, os.path.join(logging_dir, \"jsd/\", \"jsd.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde_samples(samples, real_data_test, fpath=os.path.join(logging_dir, \"kde/\", f\"kde.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = np.random.randint(0, 256) \n",
    "customer_indices = np.random.randint(0, 256, size=15)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample = ddpm.sample(1, real_cond_data_test.to(device)) \n",
    "    sample = sample.cpu().numpy() \n",
    "\n",
    "for i in customer_indices:\n",
    "    axs[0].plot(sample[0, i], alpha=0.7, label=f'Customer {i}')\n",
    "    axs[1].plot(real_data_test[0, i], alpha=0.7, label=f'Customer {i}')\n",
    "\n",
    "axs[0].set_title(\"Generated Data\")\n",
    "axs[1].set_title(\"Real Data\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(logging_dir, \"ts_sample/\", \"samples.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf437bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a long time but it works\n",
    "animator = KDEProgressionAnimator(real_data_val.cpu().numpy(), snapshots.values())\n",
    "animator.animate()\n",
    "animator.save(os.path.join(logging_dir, \"kde/\", \"kde_progression.gif\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
