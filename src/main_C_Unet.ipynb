{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import gc\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from preprocessing.house_zero_preprocessing import serve_data_hz\n",
    "\n",
    "from models.context_unet import ContextUnet\n",
    "\n",
    "import ddpm.cu_ddpm as ddpm\n",
    "\n",
    "from evaluation.pca_tsne import visualize_pca_tsne\n",
    "from evaluation.jsd import compute_jsd\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config.yml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.full_load(f)\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d-%H-%M')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "epochs = config[\"epochs\"]\n",
    "timesteps = config[\"timesteps\"]\n",
    "batch_size_config = config[\"batch_size\"]\n",
    "latent_dim = config[\"latent_dim\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "n_heads = config[\"n_heads\"]\n",
    "beta_schedule = config[\"beta_schedule\"]\n",
    "objective = config[\"objective\"]\n",
    "subset_len = config[\"subset_len\"]\n",
    "model_name = config[\"model_name\"]\n",
    "cond_model = config[\"cond_model\"]\n",
    "lr = float(config[\"lr\"])\n",
    "betas = tuple_of_floats = ast.literal_eval(config[\"betas\"])\n",
    "save_rate = int(config[\"save_rate\"])\n",
    "dataset_name = config[\"dataset\"]\n",
    "house_zero_feature_subset = config[\"house_zero_feature_subset\"]\n",
    "img_rows = int(config[\"img_rows\"])\n",
    "img_cols = int(config[\"img_cols\"])\n",
    "channels = int(config[\"channels\"])\n",
    "n_feat = int(config[\"n_feat\"])\n",
    "\n",
    "assert model_name in [\"ContextUnet\"], \"Chosen  model was not valid, the option is ContextUnet\"\n",
    "assert cond_model in {\"mlp\", \"te\", \"stft\"}, \"Chosen conditioning model was not valid, the options are mlp, te and stft\"\n",
    "if (model_name, dataset_name) == (\"ContextUnet\", \"LondonDataStore\"):\n",
    "    raise AssertionError(\"Chosen model is not compatible with chosen dataset\")\n",
    "\n",
    "log_file_name = f\"{model_name}_{cond_model}_{str(date)}\"\n",
    "tb_writer = f\"./logging/tensorboard/{log_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14035, 1, 8, 8]) torch.Size([14035, 8])\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, n_cfeat = serve_data_hz(batch_size=batch_size_config, channels=channels, feature_subset=house_zero_feature_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContextUnet(in_channels=channels, n_feat=n_feat, n_cfeat=n_cfeat, height=img_cols, cond_model=cond_model).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:05<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:04<00:00, 44.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:04<00:00, 45.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:04<00:00, 45.96it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for ep in range(epochs):\n",
    "    print(f'epoch {ep}')\n",
    "\n",
    "    # linearly decay learning rate\n",
    "    optim.param_groups[0]['lr'] = lr*(1-ep/epochs)\n",
    "\n",
    "    pbar = tqdm(train_loader, mininterval=2 )\n",
    "    epoch_loss = 0.0   # initialize epoch loss\n",
    "    n_batches = 0      # count number of batches\n",
    "    for x, c in pbar:   # x: images  c: context\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        c = c.to(x)\n",
    "        \n",
    "        # randomly mask out c\n",
    "        context_mask = torch.bernoulli(torch.zeros(c.shape[0]) + 0.9).to(device)\n",
    "        c = c * context_mask.unsqueeze(-1)\n",
    "\n",
    "        # perturb data\n",
    "        noise = torch.randn_like(x)\n",
    "        noise = noise.type(torch.float32)\n",
    "        t = torch.randint(1, timesteps + 1, (x.shape[0],)).to(device)\n",
    "        x_pert = ddpm.perturb_input(x, t, noise, beta1=betas[0], beta2=betas[1], timesteps=timesteps, device=device)\n",
    "\n",
    "        # use network to recover noise\n",
    "        time = t / timesteps\n",
    "        time = time.type(torch.float32)\n",
    "        x_pert = x_pert.type(torch.float32)\n",
    "        c = c.type(torch.float32)\n",
    "        \n",
    "        pred_noise = model(x_pert, time, c=c)\n",
    "        # loss is mean squared error between the predicted and true noise\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "        epoch_loss += loss.item()\n",
    "        n_batches += 1\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling timestep   10\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ad0aa7fa60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample, _ = ddpm.sample_ddpm_context(n_sample=1, context=None, channels=channels, height=img_cols, \n",
    "                                      device=device, timesteps=timesteps, nn_model=model, beta1=betas[0], beta2=betas[1])\n",
    "sample = sample.cpu().numpy()\n",
    "sample = np.transpose(sample, (0, 2, 3, 1))\n",
    "sample = sample.squeeze(-1)\n",
    "plt.imshow(sample.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## Without Conditioning\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 8]), torch.Size([64, 1, 8, 8]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_train, real_cond_data_train = next(iter(train_loader))\n",
    "real_data_test, real_cond_data_test = next(iter(test_loader))\n",
    "\n",
    "real_cond_data_train.shape, real_data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
