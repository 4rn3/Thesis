{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import math\n",
    "\n",
    "import gc\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from preprocessing.final_preprocessing import serve_data_unet\n",
    "\n",
    "from models.context_unet import ContextUnet\n",
    "\n",
    "import ddpm.cu_ddpm as ddpm\n",
    "\n",
    "from evaluation.pca_tsne import visualize_pca_tsne_unet\n",
    "from evaluation.jsd import compute_jsd\n",
    "from evaluation.rmse import rmse\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config_unet.yml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.full_load(f)\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d-%H-%M')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "epochs = config[\"epochs\"]\n",
    "timesteps = config[\"timesteps\"]\n",
    "batch_size_config = config[\"batch_size\"]\n",
    "latent_dim = config[\"latent_dim\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "n_heads = config[\"n_heads\"]\n",
    "beta_schedule = config[\"beta_schedule\"]\n",
    "objective = config[\"objective\"]\n",
    "model_name = config[\"model_name\"]\n",
    "cond_model = config[\"cond_model\"]\n",
    "lr = float(config[\"lr\"])\n",
    "betas = tuple_of_floats = ast.literal_eval(config[\"betas\"])\n",
    "save_rate = int(config[\"save_rate\"])\n",
    "img_rows = int(config[\"img_rows\"])\n",
    "img_cols = int(config[\"img_cols\"])\n",
    "channels = int(config[\"channels\"])\n",
    "n_feat = int(config[\"n_feat\"])\n",
    "\n",
    "assert model_name in [\"ContextUnet\"], \"Chosen  model was not valid, the option is ContextUnet\"\n",
    "assert cond_model in {\"mlp\", \"te\", \"stft\"}, \"Chosen conditioning model was not valid, the options are mlp, te and stft\"\n",
    "\n",
    "\n",
    "log_file_name = f\"{model_name}_{cond_model}_{str(date)}\"\n",
    "tb_writer = f\"./logging/tensorboard/{log_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can take a while to load\n",
    "train_loader, test_loader, n_cfeat, customer_ids, train_data, test_data = serve_data_unet(batch_size=batch_size_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContextUnet(in_channels=channels, n_feat=n_feat, n_cfeat=n_cfeat, height=img_cols, cond_model=cond_model).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "writer = SummaryWriter(tb_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = f\"./logging/weights/{log_file_name}\"\n",
    "os.makedirs(run_path)\n",
    "\n",
    "rmse_list = []\n",
    "lowest_loss = 100000\n",
    "step=0\n",
    "\n",
    "model.train()\n",
    "for ep in tqdm(range(epochs)):\n",
    "    # linearly decay learning rate\n",
    "    optim.param_groups[0]['lr'] = lr*(1-ep/epochs)\n",
    "    epoch_loss = 0.0   # initialize epoch loss\n",
    "    for i, (x, c) in enumerate(train_loader):   # x: images  c: context\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        c = c.to(x)\n",
    "        \n",
    "        # randomly mask out c\n",
    "        context_mask = torch.bernoulli(torch.zeros(c.shape[0]) + 0.9).to(device)\n",
    "        c = c * context_mask.unsqueeze(-1)\n",
    "\n",
    "        # perturb data\n",
    "        noise = torch.randn_like(x)\n",
    "        noise = noise.type(torch.float32)\n",
    "        t = torch.randint(1, timesteps + 1, (x.shape[0],)).to(device)\n",
    "        x_pert = ddpm.perturb_input(x, t, noise, beta1=betas[0], beta2=betas[1], timesteps=timesteps, device=device)\n",
    "\n",
    "        # use network to recover noise\n",
    "        time = t / timesteps\n",
    "        time = time.type(torch.float32)\n",
    "        x_pert = x_pert.type(torch.float32)\n",
    "        c = c.type(torch.float32)\n",
    "        \n",
    "        pred_noise = model(x_pert, time, c=None)\n",
    "        # loss is mean squared error between the predicted and true noise\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        if loss.item() < lowest_loss:\n",
    "            lowest_loss = loss.item()\n",
    "            best_model_params = model.state_dict()\n",
    "        \n",
    "        writer.add_scalar(\"Batch Training Loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    writer.add_scalar(\"Epoch Training Loss\", avg_epoch_loss, ep)\n",
    "    \n",
    "    if ep % 5 ==0:        \n",
    "        sample, _ = ddpm.sample_ddpm_context(n_sample=10, context=None, channels=channels, height=img_cols, \n",
    "                                      device=device, timesteps=timesteps, nn_model=model, beta1=betas[0], beta2=betas[1])\n",
    "        \n",
    "        p = sample.repeat(1, 3, 1, 1).cpu()\n",
    "        q = torch.from_numpy(test_data[:batch_size_config]).repeat(1, 3, 1, 1) \n",
    "        \n",
    "        rmse_res = rmse(p,q).item()\n",
    "        rmse_list.append(rmse_res)   \n",
    "        \n",
    "        writer.add_scalar('Epoch Training RMSE', rmse_res, ep)\n",
    "        \n",
    "        print(f'Epoch: {ep+1}, Epoch Loss: {avg_epoch_loss:.4f}, RMSE: {rmse(p,q):.4f}')\n",
    "    \n",
    "    else:\n",
    "        print(f'Epoch: {ep+1}, Epoch Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "    if ep % save_rate == 0:\n",
    "        torch.save({\n",
    "            'epoch': ep+1,\n",
    "            'diffusion_state_dict': model.state_dict(),\n",
    "            'diffusion_optim_state_dict': optim.state_dict()\n",
    "            }, os.path.join(f'{run_path}', f'ep_{ep}_mse_{avg_epoch_loss:.3f}_weights.pth'))\n",
    "    \n",
    "torch.save(best_model_params, os.path.join(f'{run_path}', 'best_model_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(sample, rows=None, cols=None, figsize=(12, 10), title=None):\n",
    "    n_images = sample.shape[0]\n",
    "    \n",
    "    if rows is None and cols is None:\n",
    "        cols = math.ceil(math.sqrt(n_images))\n",
    "        rows = math.ceil(n_images / cols)\n",
    "    elif rows is None:\n",
    "        rows = math.ceil(n_images / cols)\n",
    "    elif cols is None:\n",
    "        cols = math.ceil(n_images / rows)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    if rows > 1 or cols > 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = [axes]  \n",
    "    \n",
    "    for i in range(n_images):\n",
    "        if i < len(axes):  \n",
    "            im = axes[i].imshow(sample[i], cmap='viridis')\n",
    "            axes[i].set_title(f'Image {i+1}')\n",
    "            axes[i].axis('off')  \n",
    "    \n",
    "    for i in range(n_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, _ = ddpm.sample_ddpm_context(n_sample=10, context=None, channels=channels, height=img_cols, \n",
    "                                      device=device, timesteps=timesteps, nn_model=model, beta1=betas[0], beta2=betas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.cpu().numpy()\n",
    "sample = sample.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(sample, title=\"No conditioning train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## Without Conditioning\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_train, real_cond_data_train = next(iter(train_loader))\n",
    "real_data_test, real_cond_data_test = next(iter(test_loader))\n",
    "\n",
    "real_cond_data_train.shape, real_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_customer_ids = random.sample(range(len(customer_ids)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_tsne_unet(real_data_train, sample, customer_ids, filename=log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_train_no_cond = {}\n",
    "multi_customer_sample = sample.reshape(-1, img_cols*img_rows)\n",
    "multi_customer_real_data = real_data_train.reshape(-1, img_cols*img_rows)\n",
    "\n",
    "for i in range(multi_customer_sample.shape[1]):\n",
    "    jsd_train_no_cond[i] = compute_jsd(multi_customer_real_data[:, i], multi_customer_sample[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_tsne_unet(real_data_test, sample, customer_ids, filename=log_file_name, train_test=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_test_no_cond = {}\n",
    "multi_customer_sample = sample.reshape(-1, img_cols*img_rows)\n",
    "multi_customer_real_data = real_data_test.reshape(-1, img_cols*img_rows)\n",
    "\n",
    "for i in range(multi_customer_sample.shape[1]):\n",
    "    jsd_test_no_cond[i] = compute_jsd(multi_customer_real_data[:, i], multi_customer_sample[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Conditioning\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, _ = ddpm.sample_ddpm_context(n_sample=10, context=real_cond_data_train.to(device), channels=channels, height=img_cols, \n",
    "                                      device=device, timesteps=timesteps, nn_model=model, beta1=betas[0], beta2=betas[1])\n",
    "sample = sample.cpu().numpy()\n",
    "sample = sample.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_tsne_unet(real_data_train, sample, customer_ids, filename=log_file_name, cond=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_train_cond = {}\n",
    "multi_customer_sample = sample.reshape(-1, img_cols*img_rows)\n",
    "multi_customer_real_data = real_data_train.reshape(-1, img_cols*img_rows)\n",
    "\n",
    "for i in range(multi_customer_sample.shape[1]):\n",
    "    jsd_train_cond[i] = compute_jsd(multi_customer_real_data[:, i], multi_customer_sample[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, _ = ddpm.sample_ddpm_context(n_sample=10, context=real_cond_data_test.to(device), channels=channels, height=img_cols, \n",
    "                                      device=device, timesteps=timesteps, nn_model=model, beta1=betas[0], beta2=betas[1])\n",
    "sample = sample.cpu().numpy()\n",
    "sample = sample.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_tsne_unet(real_data_test, sample, customer_ids, filename=log_file_name, cond=True, train_test=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_test_cond = {}\n",
    "multi_customer_sample = sample.reshape(-1, img_cols*img_rows)\n",
    "multi_customer_real_data = real_data_test.reshape(-1, img_cols*img_rows)\n",
    "\n",
    "for i in range(multi_customer_sample.shape[1]):\n",
    "    jsd_test_cond[i] = compute_jsd(multi_customer_real_data[:, i], multi_customer_sample[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_data = pd.DataFrame({\n",
    "    'Train No Cond': jsd_train_no_cond,\n",
    "    'Test No Cond': jsd_test_no_cond,\n",
    "    'Train Cond': jsd_train_cond,\n",
    "    'Test Cond': jsd_test_cond\n",
    "})\n",
    "\n",
    "all_keys = set(jsd_train_no_cond.keys()) | set(jsd_test_no_cond.keys()) | set(jsd_train_cond.keys()) | set(jsd_test_cond.keys())\n",
    "\n",
    "jsd_data = pd.DataFrame({\n",
    "    'Train No Cond': [jsd_train_no_cond.get(k, None) for k in all_keys],\n",
    "    'Test No Cond': [jsd_test_no_cond.get(k, None) for k in all_keys],\n",
    "    'Train Cond': [jsd_train_cond.get(k, None) for k in all_keys],\n",
    "    'Test Cond': [jsd_test_cond.get(k, None) for k in all_keys]\n",
    "}, index=list(all_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = f'./logging/plots/JSD/'\n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "\n",
    "\n",
    "means = jsd_data.mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(means.index, means.values)\n",
    "\n",
    "plt.title('Average JSD Values for all Customers', fontsize=15)\n",
    "plt.ylabel('Average Value', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plot_dir, log_file_name+\".png\", ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_dir = f'./logging/plots/JSD/'\n",
    "\n",
    "# if not os.path.exists(plot_dir):\n",
    "#         os.makedirs(plot_dir)\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# for i, column in enumerate(jsd_data.columns):\n",
    "#     axs[i].bar(jsd_data.index, jsd_data[column])\n",
    "#     axs[i].set_title(column)\n",
    "#     axs[i].set_xlabel('Customers')\n",
    "#     axs[i].set_ylabel('JSD')\n",
    "#     axs[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(plot_dir, log_file_name+\".png\", ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./logging/logs\"\n",
    "log_file_path = os.path.join(log_dir, log_file_name + \".txt\")\n",
    "\n",
    "jsd_data.to_csv(os.path.join(log_dir, log_file_name + \".csv\"))\n",
    "\n",
    "with open(log_file_path, 'w') as log_file:\n",
    "    log_file.write(\"Config:\\n\")\n",
    "    for key, value in config.items():\n",
    "        log_file.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    log_file.write(\"\\n\\nRMSE Values:\\n\")\n",
    "    for rmse in rmse_list:\n",
    "        log_file.write(f\"{rmse}\\n\")\n",
    "    \n",
    "    log_file.write(\"\\n\\nJSD Values:\\n\")\n",
    "    log_file.write(str(os.path.join(log_dir, log_file_name + \".csv\")))\n",
    "\n",
    "print(f\"Log file created at: {log_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
