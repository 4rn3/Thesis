{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import gc\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from preprocessing.final_preprocessing import serve_data\n",
    "\n",
    "from models.transformer_encoder import TransEncoder\n",
    "from models.baseline import BaseLineModel\n",
    "\n",
    "from ddpm.ddpm import GaussianDiffusion1D\n",
    "\n",
    "from evaluation.pca_tsne import visualize_pca_tsne\n",
    "from evaluation.jsd import compute_jsd\n",
    "from evaluation.rmse import rmse\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config.yml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.full_load(f)\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d-%H-%M')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "seq_len = config[\"seq_len\"]\n",
    "epochs = config[\"epochs\"]\n",
    "timesteps = config[\"timesteps\"]\n",
    "batch_size_config = config[\"batch_size\"]\n",
    "latent_dim = config[\"latent_dim\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "n_heads = config[\"n_heads\"]\n",
    "beta_schedule = config[\"beta_schedule\"]\n",
    "objective = config[\"objective\"]\n",
    "model_name = config[\"model_name\"]\n",
    "cond_model = config[\"cond_model\"]\n",
    "lr = float(config[\"lr\"])\n",
    "betas = tuple_of_floats = ast.literal_eval(config[\"betas\"])\n",
    "save_rate = int(config[\"save_rate\"])\n",
    "\n",
    "img_rows = int(config[\"img_rows\"])\n",
    "img_cols = int(config[\"img_cols\"])\n",
    "channels = int(config[\"channels\"])\n",
    "n_feat = int(config[\"n_feat\"])\n",
    "num_customers = int(config[\"num_customers\"])\n",
    "\n",
    "assert model_name in [\"BaseLine\", \"TransEncoder\"], \"Chosen  model was not valid, the options are BaseLine or TransEncoder\"\n",
    "assert cond_model in {\"mlp\", \"te\", \"fft\", \"stft\"}, \"Chosen conditioning model was not valid, the options are mlp, te, fft and stft\"\n",
    "\n",
    "log_file_name = f\"{model_name}_{cond_model}_{str(date)}\"\n",
    "tb_writer = f\"./logging/tensorboard/{log_file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, train_cols, test_cols, test_data, features, cond_features = serve_data(seq_len=seq_len, batch_size=batch_size_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"TransEncoder\":\n",
    "    model = model = TransEncoder(features = features, latent_dim = latent_dim,num_heads = n_heads, num_layers = num_layers, cond_features=cond_features, cond_model=cond_model, device=device, seq_len=seq_len)\n",
    "if model_name == \"BaseLine\":\n",
    "    model = BaseLineModel(seq_len=seq_len, hidden_dim=latent_dim, cond_dim=cond_features, cond_model=cond_model, device=device, channels=features)\n",
    "    \n",
    "\n",
    "ddpm = GaussianDiffusion1D(model, seq_length = seq_len, timesteps = timesteps, objective = objective, loss_type = 'l2', beta_schedule = beta_schedule)\n",
    "ddpm = ddpm.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(ddpm.parameters(), lr = lr, betas = betas)\n",
    "writer = SummaryWriter(tb_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = f\"./logging/weights/{log_file_name}\"\n",
    "os.makedirs(run_path)\n",
    "\n",
    "rmse_list = []\n",
    "lowest_loss = 100000\n",
    "step=0\n",
    "\n",
    "for running_epoch in tqdm(range(epochs)):\n",
    "    running_loss = 0.0\n",
    "    for i, (data, cond_data) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        cond_data = cond_data.float()\n",
    "        cond_data = cond_data.to(device)\n",
    "                \n",
    "        batch_size = data.shape[0]\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        loss = ddpm(data, cond_data)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        \n",
    "        if loss.item() < lowest_loss:\n",
    "            lowest_loss = loss.item()\n",
    "            best_model_params = model.state_dict()\n",
    "        \n",
    "        writer.add_scalar(\"Batch Training Loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "    \n",
    "    avg_epoch_loss = running_loss / len(train_loader)\n",
    "    writer.add_scalar(\"Epoch Training Loss\", avg_epoch_loss, running_epoch)\n",
    "    \n",
    "    if running_epoch % 5 ==0:        \n",
    "        with torch.no_grad():\n",
    "            sample = ddpm.sample(batch_size_config)\n",
    "        \n",
    "        p = sample.cpu()\n",
    "        q = torch.from_numpy(test_data[:batch_size_config])\n",
    "            \n",
    "        rmse_res = rmse(p,q).item()\n",
    "        rmse_list.append(rmse_res)\n",
    "        \n",
    "        writer.add_scalar('Epoch Training RMSE', rmse_res, running_epoch)\n",
    "        \n",
    "        print(f'Epoch: {running_epoch+1}, Epoch Loss: {avg_epoch_loss:.4f}, RMSE: {rmse_res:.4f}')\n",
    "    \n",
    "    else:\n",
    "        print(f'Epoch: {running_epoch+1}, Epoch Loss: {avg_epoch_loss:.4f}')\n",
    "            \n",
    "            \n",
    "    if running_epoch % save_rate == 0:\n",
    "        torch.save({\n",
    "            'epoch': running_epoch+1,\n",
    "            'diffusion_state_dict': ddpm.state_dict(),\n",
    "            'diffusion_optim_state_dict': optim.state_dict()\n",
    "            }, os.path.join(f'{run_path}', f'ep_{running_epoch}_mse_{avg_epoch_loss:.3f}_weights.pth'))\n",
    "\n",
    "torch.save(best_model_params, os.path.join(f'{run_path}', 'best_model_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samples = ddpm.sample(batch_size_config)\n",
    "    samples = samples.cpu().numpy()\n",
    "    samples = samples.transpose(0, 2, 1)\n",
    "\n",
    "print(f\"Samples shape: {samples.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## Without Conditioning\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_train, real_cond_data_train = next(iter(train_loader))\n",
    "real_data_test, real_cond_data_test = next(iter(test_loader))\n",
    "\n",
    "real_cond_data_train.shape, real_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_customer_ids = random.sample(train_cols, num_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(train_customer_ids):\n",
    "    real_feature = np.expand_dims(real_data_train[:, idx, :].cpu().numpy(), axis=-1)\n",
    "    gen_feature = np.expand_dims(samples[:, :, idx], axis=-1)\n",
    "    \n",
    "    visualize_pca_tsne(ori_data=real_feature, fake_data=gen_feature, seq_len=seq_len, train_test=\"train\", filename=log_file_name, cond=False, feature=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_customer_ids = random.sample(test_cols, num_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(test_customer_ids):\n",
    "    real_feature = np.expand_dims(real_data_test[:, idx, :].cpu().numpy(), axis=-1)\n",
    "    gen_feature = np.expand_dims(samples[:, :, idx], axis=-1)\n",
    "    \n",
    "    visualize_pca_tsne(ori_data=real_feature, fake_data=gen_feature, seq_len=seq_len, train_test=\"test\", filename=log_file_name, cond=False, feature=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_ids = train_customer_ids + test_customer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jsd_no_con_list = []\n",
    "test_jsd_no_con_list = []\n",
    "\n",
    "for idx, feature in enumerate(customer_ids):\n",
    "    real_feature_train = real_data_train[:, idx, :].cpu().numpy()\n",
    "    real_feature_test = real_data_test[:, idx, :].cpu().numpy()\n",
    "    gen_feature = samples[:, :, idx]\n",
    "    \n",
    "    jsd_no_con_train = compute_jsd(real_feature_train, samples)\n",
    "    jsd_no_con_test = compute_jsd(real_feature_test, samples)\n",
    "    \n",
    "    train_jsd_no_con_list.append(jsd_no_con_train)\n",
    "    test_jsd_no_con_list.append(jsd_no_con_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cond_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cond_samples_train = ddpm.sample(real_cond_data_train.shape[0], real_cond_data_train.to(device))\n",
    "    cond_samples_train = cond_samples_train.cpu().numpy()\n",
    "    cond_samples_train = cond_samples_train.transpose(0, 2, 1)\n",
    "\n",
    "print(f\"Samples shape: {cond_samples_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(train_customer_ids):\n",
    "    real_feature = np.expand_dims(real_data_train[:, idx, :].cpu().numpy(), axis=-1)\n",
    "    gen_feature = np.expand_dims(cond_samples_train[:, :, idx], axis=-1)\n",
    "    \n",
    "    visualize_pca_tsne(ori_data=real_feature, fake_data=gen_feature, seq_len=seq_len, train_test=\"train\", filename=log_file_name, cond=True, feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cond_samples_test = ddpm.sample(real_cond_data_test.shape[0], real_cond_data_test.to(device))\n",
    "    cond_samples_test = cond_samples_test.cpu().numpy()\n",
    "    cond_samples_test = cond_samples_test.transpose(0, 2, 1)\n",
    "\n",
    "print(f\"Samples shape: {cond_samples_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(test_customer_ids):\n",
    "    real_feature = np.expand_dims(real_data_train[:, idx, :].cpu().numpy(), axis=-1)\n",
    "    gen_feature = np.expand_dims(cond_samples_test[:, :, idx], axis=-1)\n",
    "    \n",
    "    visualize_pca_tsne(ori_data=real_feature, fake_data=gen_feature, seq_len=seq_len, train_test=\"test\", filename=log_file_name, cond=True, feature=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jsd_con_list = []\n",
    "test_jsd_con_list = []\n",
    "\n",
    "for idx, feature in enumerate(customer_ids):\n",
    "    real_feature_train = real_data_train[:, idx, :].cpu().numpy()\n",
    "    real_feature_test = real_data_test[:, idx, :].cpu().numpy()\n",
    "    gen_feature_train = cond_samples_train[:, :, idx]\n",
    "    gen_feature_test = cond_samples_test[:, :, idx]\n",
    "    \n",
    "    jsd_con_train = compute_jsd(real_feature_train, gen_feature_train)\n",
    "    jsd_con_test = compute_jsd(real_feature_test, gen_feature_test)\n",
    "    \n",
    "    train_jsd_con_list.append(jsd_con_train)\n",
    "    test_jsd_con_list.append(jsd_con_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"train_jsd_con\": train_jsd_con_list,\n",
    "    \"train_jsd_no_con\": train_jsd_no_con_list,\n",
    "    \"test_jsd_con\": test_jsd_con_list,\n",
    "    \"test_jsd_no_con\": test_jsd_no_con_list\n",
    "}\n",
    "\n",
    "jsd_data = pd.DataFrame(data, index=customer_ids)\n",
    "jsd_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./logging/plots/JSD/'):\n",
    "    os.makedirs('./logging/plots/JSD/')\n",
    "\n",
    "jsd_data.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "plot_dir = f'./logging/plots/JSD/'\n",
    "plt.savefig(os.path.join(plot_dir, log_file_name+\".png\", ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./logging/logs\"\n",
    "log_file_path = os.path.join(log_dir, log_file_name + \".txt\")\n",
    "\n",
    "jsd_data.to_csv(os.path.join(log_dir, log_file_name + \".csv\"))\n",
    "\n",
    "with open(log_file_path, 'w') as log_file:\n",
    "    log_file.write(\"Config:\\n\")\n",
    "    for key, value in config.items():\n",
    "        log_file.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    log_file.write(\"\\n\\nRMSE Values:\\n\")\n",
    "    for rmse in rmse_list:\n",
    "        log_file.write(f\"{rmse}\\n\")\n",
    "    \n",
    "    log_file.write(\"\\n\\nJSD Values:\\n\")\n",
    "    log_file.write(str(os.path.join(log_dir, log_file_name + \".csv\")))\n",
    "\n",
    "print(f\"Log file created at: {log_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = torch.load(\"./logging/weights/TransEncoder_te_2025-02-19-19-39/best_model_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
